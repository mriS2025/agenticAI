{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f3775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create RAG using OPENAI embeddings and Chroma db\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf63c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "openAIEmbeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d9512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" #this is to load complex excels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "loader = UnstructuredExcelLoader(\"/Users/kuldeep/Documents/mriduladata/agenticAICourse/agentic2.0/data/SimplifiedPY2026-NA-Baseline-and-Alternative-T&D-Standards.xlsx\", mode=\"elements\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_docs=text_splitter.split_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67940716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using chroma db\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "\n",
    "vectorstore = Chroma.from_documents(filter_complex_metadata(new_docs), openAIEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180ced3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"what is FIPS code for Bacon county?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"What are 2026 Network Adequacy Time and Distance Rules for Cardiothoracic Surgery for Rural Counties in GA? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel , Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6425cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicSelectionParser(BaseModel):\n",
    "    Topic: str=Field(description=\"Selected Topic\")\n",
    "    Reasoning: str=Field(description=\"Reasoning behind topic selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5445062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dbe624",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=PydanticOutputParser(pydantic_object=TopicSelectionParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f5d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "import operator\n",
    "from typing import List\n",
    "from pydantic import BaseModel , Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph,END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd40686",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fcee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model=ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
    "output=model.invoke(\"hi\")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisorFunc(state:AgentState):\n",
    "    \n",
    "    question=state[\"messages\"][-1]\n",
    "    \n",
    "    print(\"Question\",question)\n",
    "    \n",
    "    template=\"\"\"\n",
    "    Your task is to classify the given user query into one of the following categories: [2026 Network Adequacy Rules for GA,Something else but not real-time, Something else but I need to pull from internet to get latest information]. \n",
    "    Only respond with the category name and nothing else.\n",
    "\n",
    "    User query: {question}\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "  \n",
    "\n",
    "    prompt= PromptTemplate(\n",
    "        template=template,\n",
    "        input_variable=[\"question\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "    \n",
    "    \n",
    "    chain= prompt | model | parser\n",
    "    \n",
    "    response = chain.invoke({\"question\":question})\n",
    "    \n",
    "    print(\"Parsed response:\", response)\n",
    "    \n",
    "    return {\"messages\": [response.Topic]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76011391",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"what is a today weather?\"]}\n",
    "supervisorFunc(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1536d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"What are 2026 Network Adequacy Time and Distance Rules for Cardiothoracic Surgery for Rural Counties in GA? \"]}\n",
    "supervisorFunc(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c91c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"who was first president of india?\"]}\n",
    "supervisorFunc(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88007e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def routerFunc(state:AgentState):\n",
    "    print(\"-> ROUTER ->\")\n",
    "    \n",
    "    last_message=state[\"messages\"][-1]\n",
    "    print(\"last_message:\", last_message)\n",
    "    \n",
    "    if \"adequacy\" in last_message.lower():\n",
    "        return \"RAG Call\"\n",
    "    elif \"internet\" in last_message.lower():\n",
    "        return \"WEB Call\"\n",
    "    else:\n",
    "        return \"LLM Call\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77432e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46449182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Function\n",
    "def ragFunc(state:AgentState):\n",
    "    print(\"-> RAG Call ->\")\n",
    "    \n",
    "    question = state[\"messages\"][0]\n",
    "    \n",
    "    prompt=PromptTemplate(\n",
    "        template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\",\n",
    "        \n",
    "        input_variables=['context', 'question']\n",
    "    )\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result = rag_chain.invoke(question)\n",
    "    return  {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"how many miles for Cardiothoracic Surgery in 2026 filling?\"]}\n",
    "ragFunc(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"What are 2026 Network Adequacy Time and Distance Rules for Cardiothoracic Surgery for Rural Counties in GA? \"]}\n",
    "ragFunc(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b995383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Function\n",
    "def llmFunc(state:AgentState):\n",
    "    print(\"-> LLM Call ->\")\n",
    "    question = state[\"messages\"][0]\n",
    "    \n",
    "    # Normal LLM call\n",
    "    complete_query = \"Anwer the follow question with your knowledge of the real world. Following is the user question: \" + question\n",
    "    response = model.invoke(complete_query)\n",
    "    return {\"messages\": [response.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WEB Function create a RAG\n",
    "from langchain_community.document_loaders import SeleniumURLLoader\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45676dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load documents\n",
    "loader=SeleniumURLLoader(\n",
    "        urls=[\"https://www.nextgen.com/blog/industry-news/new-cms-regulation-establishes-maximum-appointment-wait-time-standards-for-medicaid\"]\n",
    "    )\n",
    "documents=loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split documents\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True)\n",
    "\n",
    "new_docs=text_splitter.split_documents(documents)\n",
    "new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "webVectorStore = Chroma.from_documents(new_docs, openAIEmbeddings)\n",
    "webRetriever=webVectorStore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d29f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "webRetriever.invoke(\"what is new rule starting 2027?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3861c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webFunc(state:AgentState):\n",
    "    print(\"-> WEB Call ->\")\n",
    "    question = state[\"messages\"][0]\n",
    "\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "        Question: {question}\n",
    "        Context: {context}\n",
    "        Answer:\"\"\",\n",
    "        input_variables=['context', 'question']\n",
    "    )\n",
    "    rag_chain = (\n",
    "        {\"context\": webRetriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result = rag_chain.invoke(question)\n",
    "    return  {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"what is latest 2027 Network Adequacy requirements?\"]}\n",
    "webFunc(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cdaab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,END\n",
    "workflow=StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6713ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"Supervisor\",supervisorFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f8a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"RAG\",ragFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"LLM\",llmFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d247294",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"WEB\",webFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.set_entry_point(\"Supervisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28ed614",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_conditional_edges(\n",
    "    \"Supervisor\",\n",
    "    router,\n",
    "    {\n",
    "        \"RAG Call\": \"RAG\",\n",
    "        \"LLM Call\": \"LLM\",\n",
    "        \"WEB Call\": \"WEB\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_edge(\"RAG\",END)\n",
    "workflow.add_edge(\"LLM\",END)\n",
    "workflow.add_edge(\"WEB\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f62bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "app=workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bdb5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd0ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"How many miles for Cardiothoracic surgery in Network Adequacy?\"]}\n",
    "app.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"What are 2026 network adequacy facility type specialties\"]}\n",
    "app.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf11807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "from langsmith import Client\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Define the examples for the dataset\n",
    "examples = [\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What are 2026 Network Adequacy Time and Distance Rules for Cardiothoracic Surgery for Rural Counties in GA? \"},\n",
    "        \"outputs\": {\"answer\": \"2026 Network Adequacy Time and Distance Rules for Cardiothoracic Surgery for Rural Counties in GA are Baseline Distance: 90 Miles, Baseline Time: 110 Minutes and Alternative Distance: 90 Miles\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What are 2026 Network Adequacy rural counties in GA?\"},\n",
    "        \"outputs\": {\"answer\": \"GA Rural counties are Appling, Bacon, Calhoun, Charlton, Clay, Early, Glascock, Hancock, Jeff Davis, Lincoln, McIntosh, Marion, Meriwether, Miller, Mitchell, Quitman, Randolh, Stewart, Telfair, Warren, Wheeler and Wikes.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What are 2026 network adequacy facility type specialties?\"},\n",
    "        \"outputs\": {\"answer\": \"2026 network adequacy facility type specialties are Acute Inpatient Hospitals(Must have emergency services available 24/7), Cardiac Catherization Services, Cardiac Surgery Program, Critical Care Services - Intensive Care Units (ICU), Diagnostic Radiology (Free-standing; hospital outpatient; ambulatory health facilities with Dx Radiology),Inpatient or Residential Behavioral Health Facility Services, Mammography, Outpatient Infusion/ Chemotherapy, Skilled Nursing Facilities, Surgical Services (Ambulatory Surgical Centers and Outpatient Hospital), Urgent Care.\"},\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset and examples in LangSmith\n",
    "dataset_name = \"2026 NetworkAdequcy Q&A\"\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    client.create_examples(\n",
    "        dataset_id=dataset.id,\n",
    "        examples=examples\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d27936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade output schema\n",
    "from langchain_openai import ChatOpenAI\n",
    "class CorrectnessGrade(TypedDict):\n",
    "    # Note that the order in the fields are defined is the order in which the model will generate them.\n",
    "    # It is useful to put explanations before responses because it forces the model to think through\n",
    "    # its final response before generating it:\n",
    "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
    "    correct: Annotated[bool, ..., \"True if the answer is correct, False otherwise.\"]\n",
    "\n",
    "\n",
    "# Grade prompt\n",
    "correctness_instructions = \"\"\"You are a teacher grading a quiz. \n",
    "\n",
    "You will be given a QUESTION, the GROUND TRUTH (correct) ANSWER, and the STUDENT ANSWER. \n",
    "\n",
    "Here is the grade criteria to follow:\n",
    "(1) Grade the student answers based ONLY on their factual accuracy relative to the ground truth answer. \n",
    "(2) Ensure that the student answer does not contain any conflicting statements.\n",
    "(3) It is OK if the student answer contains more information than the ground truth answer, as long as it is factually accurate relative to the  ground truth answer.\n",
    "\n",
    "Correctness:\n",
    "A correctness value of True means that the student's answer meets all of the criteria.\n",
    "A correctness value of False means that the student's answer does not meet all of the criteria.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \n",
    "\n",
    "Avoid simply stating the correct answer at the outset.\"\"\"\n",
    "\n",
    "# Grader LLM\n",
    "grader_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).with_structured_output(\n",
    "    CorrectnessGrade, method=\"json_schema\", strict=True\n",
    ")\n",
    "\n",
    "\n",
    "def correctness(inputs: dict, outputs: dict, reference_outputs: dict) -> bool:\n",
    "    \"\"\"An evaluator for RAG answer accuracy\"\"\"\n",
    "    answers = f\"\"\"\\\n",
    "QUESTION: {inputs['question']}\n",
    "GROUND TRUTH ANSWER: {reference_outputs['answer']}\n",
    "STUDENT ANSWER: {outputs['answer']}\"\"\"\n",
    "\n",
    "    # Run evaluator\n",
    "    grade = grader_llm.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": correctness_instructions},\n",
    "            {\"role\": \"user\", \"content\": answers},\n",
    "        ]\n",
    "    )\n",
    "    return grade[\"correct\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call original RAG model with same questions\n",
    "def target(inputs: dict) -> dict:\n",
    "    answer = state[\"messages\"][-1]\n",
    "    return {\"answer\": answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to Application\n",
    "def validator_node(state: AgentState):\n",
    "    print(f\"state: {state}\")\n",
    "    answer = state[\"messages\"][-1]\n",
    "    print(f\"answer: {answer}\")\n",
    "    dataset_name = \"2026 NetworkAdequcy Q&A\"\n",
    "    experiment_results = client.evaluate(\n",
    "        target,# replace with output from each node\n",
    "        data = dataset_name,\n",
    "        evaluators=[correctness],\n",
    "        experiment_prefix=\"rag-doc-relevance\",\n",
    "        metadata={\"version\": \"LCEL context, gpt-4-0125-preview\"},\n",
    "    )\n",
    "    print(experiment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf2084",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = state[\"messages\"][-1]\n",
    "print(f\"answer: {answer}\") # answer is not getting captured from graph so validator function always say incorrect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
